{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#0f0f1a',\n",
    "    'axes.facecolor':   '#1a1a2e',\n",
    "    'axes.edgecolor':   '#444466',\n",
    "    'axes.labelcolor':  '#e0e0f0',\n",
    "    'xtick.color':      '#aaaacc',\n",
    "    'ytick.color':      '#aaaacc',\n",
    "    'text.color':       '#e0e0f0',\n",
    "    'grid.color':       '#2a2a4a',\n",
    "    'grid.linestyle':   '--',\n",
    "    'grid.linewidth':   0.5,\n",
    "    'font.family':      'DejaVu Sans',\n",
    "    'font.size':        11\n",
    "})\n",
    "\n",
    "PRIMARY   = '#7b5ea7'\n",
    "SECONDARY = '#00c9a7'\n",
    "DANGER    = '#ff6b6b'\n",
    "HIGHLIGHT = '#ffd166'\n",
    "PALETTE   = [PRIMARY, SECONDARY, DANGER, HIGHLIGHT, '#4ecdc4', '#a8dadc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_data.csv')\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Null values:\\n{df.isnull().sum()}')\n",
    "print(f'Duplicates: {df.duplicated().sum()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "for col in ['person_age', 'person_income', 'person_emp_exp']:\n",
    "    cap = df[col].quantile(0.99)\n",
    "    df  = df[df[col] <= cap]\n",
    "\n",
    "df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].map({'Yes': 1, 'No': 0})\n",
    "df['person_gender']                  = df['person_gender'].map({'male': 1, 'female': 0})\n",
    "\n",
    "print(f'Shape after cleaning: {df.shape}')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_order  = [['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate']]\n",
    "ordinal_features = ['person_education']\n",
    "nominal_features = ['person_home_ownership', 'loan_intent']\n",
    "numeric_features = [\n",
    "    'person_age', 'person_income', 'person_emp_exp',\n",
    "    'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
    "    'cb_person_cred_hist_length', 'credit_score',\n",
    "    'previous_loan_defaults_on_file', 'person_gender'\n",
    "]\n",
    "\n",
    "X = df.drop(columns=['loan_status'])\n",
    "y = df['loan_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {X_train.shape}  |  Test: {X_test.shape}')\n",
    "print(f'Class balance \u2014 0: {(y==0).sum()}, 1: {(y==1).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',     'passthrough',                                    numeric_features),\n",
    "        ('ordinal', OrdinalEncoder(categories=education_order),       ordinal_features),\n",
    "        ('nominal', OneHotEncoder(drop='first', sparse_output=False), nominal_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',   DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__max_depth':        [4, 6, 8, 10, 12, None],\n",
    "    'classifier__min_samples_leaf': [1, 5, 10, 20, 50],\n",
    "    'classifier__criterion':        ['gini', 'entropy'],\n",
    "    'classifier__min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best ROC-AUC (CV): {grid_search.best_score_:.4f}')\n",
    "print(f'Best params: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_tree  = best_model.named_steps['classifier']\n",
    "\n",
    "print(f'Tree depth:  {best_tree.get_depth()}')\n",
    "print(f'Tree leaves: {best_tree.get_n_leaves()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cost-Complexity Pruning (alpha sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_fit = best_model.named_steps['preprocessor']\n",
    "X_train_t = preprocessor_fit.transform(X_train)\n",
    "X_test_t  = preprocessor_fit.transform(X_test)\n",
    "\n",
    "path = DecisionTreeClassifier(\n",
    "    class_weight='balanced', random_state=42\n",
    ").cost_complexity_pruning_path(X_train_t, y_train)\n",
    "\n",
    "ccp_alphas = path.ccp_alphas[:-1]\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "for alpha in ccp_alphas:\n",
    "    dt = DecisionTreeClassifier(\n",
    "        class_weight='balanced', random_state=42,\n",
    "        ccp_alpha=alpha,\n",
    "        **{k.replace('classifier__', ''): v\n",
    "           for k, v in grid_search.best_params_.items()\n",
    "           if k != 'classifier__ccp_alpha'}\n",
    "    )\n",
    "    dt.fit(X_train_t, y_train)\n",
    "    train_scores.append(roc_auc_score(y_train, dt.predict_proba(X_train_t)[:, 1]))\n",
    "    test_scores.append(roc_auc_score(y_test,  dt.predict_proba(X_test_t)[:, 1]))\n",
    "\n",
    "best_alpha_idx = np.argmax(test_scores)\n",
    "best_ccp_alpha = ccp_alphas[best_alpha_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(ccp_alphas, train_scores, color=SECONDARY, lw=2, label='Train ROC-AUC')\n",
    "ax.plot(ccp_alphas, test_scores,  color=DANGER,    lw=2, label='Test ROC-AUC')\n",
    "ax.axvline(best_ccp_alpha, color=HIGHLIGHT, linestyle='--', lw=1.5,\n",
    "           label=f'Optimal alpha = {best_ccp_alpha:.5f}')\n",
    "ax.set_xlabel('ccp_alpha')\n",
    "ax.set_ylabel('ROC-AUC')\n",
    "ax.set_title('Cost-Complexity Pruning Path', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal ccp_alpha: {best_ccp_alpha:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_params = {k.replace('classifier__', ''): v\n",
    "                 for k, v in grid_search.best_params_.items()}\n",
    "pruned_params['ccp_alpha'] = best_ccp_alpha\n",
    "\n",
    "final_tree = DecisionTreeClassifier(\n",
    "    class_weight='balanced', random_state=42,\n",
    "    **pruned_params\n",
    ")\n",
    "final_tree.fit(X_train_t, y_train)\n",
    "\n",
    "print(f'Pruned tree depth:  {final_tree.get_depth()}')\n",
    "print(f'Pruned tree leaves: {final_tree.get_n_leaves()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation on Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_fit),\n",
    "    ('classifier',   final_tree)\n",
    "])\n",
    "\n",
    "cv_metrics = {}\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    scores = cross_val_score(final_pipeline, X_train, y_train,\n",
    "                             cv=cv, scoring=metric, n_jobs=-1)\n",
    "    cv_metrics[metric] = scores\n",
    "    print(f'{metric:12s}: {scores.mean():.4f} (+/- {scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "metric_labels = list(cv_metrics.keys())\n",
    "means  = [cv_metrics[m].mean() for m in metric_labels]\n",
    "stds   = [cv_metrics[m].std()  for m in metric_labels]\n",
    "colors = [PRIMARY, SECONDARY, DANGER, HIGHLIGHT, '#4ecdc4']\n",
    "\n",
    "bars = ax.bar(metric_labels, means, yerr=stds, capsize=6,\n",
    "              color=colors, edgecolor='none',\n",
    "              error_kw=dict(ecolor='#ffffff', lw=1.5))\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
    "            f'{mean:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylim(0, 1.12)\n",
    "ax.set_title('5-Fold Cross-Validation Metrics (Pruned Tree)', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('Score')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = final_tree.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "thresholds    = np.linspace(0.01, 0.99, 200)\n",
    "f1_scores     = [f1_score(y_test, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "optimal_idx   = np.argmax(f1_scores)\n",
    "optimal_thr   = thresholds[optimal_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(thresholds, f1_scores, color=PRIMARY, lw=2)\n",
    "ax.axvline(optimal_thr, color=HIGHLIGHT, linestyle='--', lw=1.5,\n",
    "           label=f'Optimal threshold = {optimal_thr:.3f}')\n",
    "ax.scatter([optimal_thr], [f1_scores[optimal_idx]], color=HIGHLIGHT, s=80, zorder=5)\n",
    "ax.set_xlabel('Decision Threshold')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('F1 Score vs Decision Threshold', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal threshold: {optimal_thr:.4f}')\n",
    "print(f'Best F1 at threshold: {f1_scores[optimal_idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "y_pred_optimal = (y_proba >= optimal_thr).astype(int)\n",
    "\n",
    "def get_metrics(y_true, y_pred, y_prob):\n",
    "    return {\n",
    "        'Accuracy':  accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall':    recall_score(y_true, y_pred),\n",
    "        'F1':        f1_score(y_true, y_pred),\n",
    "        'ROC-AUC':   roc_auc_score(y_true, y_prob),\n",
    "        'PR-AUC':    average_precision_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "metrics_default = get_metrics(y_test, y_pred_default, y_proba)\n",
    "metrics_optimal = get_metrics(y_test, y_pred_optimal, y_proba)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Threshold=0.50':               metrics_default,\n",
    "    f'Threshold={optimal_thr:.3f}': metrics_optimal\n",
    "})\n",
    "print(results_df.to_string(float_format='{:.4f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, y_pred, title in zip(\n",
    "    axes,\n",
    "    [y_pred_default, y_pred_optimal],\n",
    "    ['Confusion Matrix (Threshold=0.50)', f'Confusion Matrix (Threshold={optimal_thr:.3f})']\n",
    "):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='magma',\n",
    "                xticklabels=['No Default', 'Default'],\n",
    "                yticklabels=['No Default', 'Default'],\n",
    "                linewidths=1, linecolor='#0f0f1a',\n",
    "                annot_kws={'size': 13, 'weight': 'bold'})\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=10)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc     = roc_auc_score(y_test, y_proba)\n",
    "axes[0].plot(fpr, tpr, color=PRIMARY, lw=2.5, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='#666680', linestyle='--', lw=1.2, label='Random Classifier')\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1, color=PRIMARY)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].yaxis.grid(True)\n",
    "axes[0].set_axisbelow(True)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "axes[1].plot(recall_vals, precision_vals, color=SECONDARY, lw=2.5,\n",
    "             label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "axes[1].fill_between(recall_vals, precision_vals, alpha=0.1, color=SECONDARY)\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].yaxis.grid(True)\n",
    "axes[1].set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report (Optimal Threshold):')\n",
    "print(classification_report(y_test, y_pred_optimal,\n",
    "                             target_names=['No Default', 'Default']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Gini Impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_feature_names = (\n",
    "    preprocessor_fit\n",
    "    .named_transformers_['nominal']\n",
    "    .get_feature_names_out(nominal_features)\n",
    ").tolist()\n",
    "\n",
    "all_feature_names = numeric_features + ordinal_features + ohe_feature_names\n",
    "\n",
    "importances = final_tree.feature_importances_\n",
    "feat_df = (\n",
    "    pd.DataFrame({'feature': all_feature_names, 'importance': importances})\n",
    "    .sort_values('importance', ascending=True)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, max(6, len(feat_df) * 0.35)))\n",
    "bar_colors = [PRIMARY if v >= feat_df['importance'].median() else '#444466'\n",
    "              for v in feat_df['importance']]\n",
    "ax.barh(feat_df['feature'], feat_df['importance'], color=bar_colors, edgecolor='none')\n",
    "ax.set_xlabel('Gini Importance')\n",
    "ax.set_title('Random Forest Feature Importances', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor=PRIMARY,  label='Above median importance'),\n",
    "    mpatches.Patch(facecolor='#444466', label='Below median importance')\n",
    "]\n",
    "ax.legend(handles=legend_elements, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 10 most important features:')\n",
    "print(\n",
    "    feat_df.sort_values('importance', ascending=False)\n",
    "    .head(10)\n",
    "    .to_string(index=False, float_format='{:.4f}'.format)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Tree Visualization (Top 4 Levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(26, 10), facecolor='#0f0f1a')\n",
    "ax.set_facecolor('#0f0f1a')\n",
    "\n",
    "plot_tree(\n",
    "    final_tree,\n",
    "    max_depth=4,\n",
    "    feature_names=all_feature_names,\n",
    "    class_names=['No Default', 'Default'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=True,\n",
    "    proportion=False,\n",
    "    fontsize=8,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('Random Forest Structure (Max Depth = 4 for readability)',\n",
    "             fontsize=14, fontweight='bold', pad=14, color='#e0e0f0')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Depth vs. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths   = range(1, 21)\n",
    "train_aucs, test_aucs = [], []\n",
    "\n",
    "for d in max_depths:\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=d, class_weight='balanced', random_state=42\n",
    "    )\n",
    "    dt.fit(X_train_t, y_train)\n",
    "    train_aucs.append(roc_auc_score(y_train, dt.predict_proba(X_train_t)[:, 1]))\n",
    "    test_aucs.append(roc_auc_score(y_test,  dt.predict_proba(X_test_t)[:, 1]))\n",
    "\n",
    "best_depth_idx = np.argmax(test_aucs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "ax.plot(list(max_depths), train_aucs, color=SECONDARY, lw=2.5, marker='o',\n",
    "        markersize=5, label='Train ROC-AUC')\n",
    "ax.plot(list(max_depths), test_aucs,  color=DANGER, lw=2.5, marker='o',\n",
    "        markersize=5, label='Test ROC-AUC')\n",
    "ax.axvline(list(max_depths)[best_depth_idx], color=HIGHLIGHT, linestyle='--', lw=1.5,\n",
    "           label=f'Best test depth = {list(max_depths)[best_depth_idx]}')\n",
    "ax.set_xlabel('Max Depth')\n",
    "ax.set_ylabel('ROC-AUC')\n",
    "ax.set_title('Overfitting Analysis: Depth vs ROC-AUC', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for status, color, label in zip([0, 1], [SECONDARY, DANGER], ['No Default (0)', 'Default (1)']):\n",
    "    mask = (y_test == status).values\n",
    "    ax.hist(y_proba[mask], bins=60, alpha=0.7, color=color, label=label, edgecolor='none')\n",
    "\n",
    "ax.axvline(0.5, color='#ffffff', lw=1.5, linestyle='--', label='Threshold = 0.50')\n",
    "ax.axvline(optimal_thr, color=HIGHLIGHT, lw=1.5, linestyle='-.',\n",
    "           label=f'Optimal Threshold = {optimal_thr:.3f}')\n",
    "ax.set_xlabel('Predicted Probability of Default')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Predicted Probability Distribution by True Class',\n",
    "             fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC', 'PR-AUC'],\n",
    "    'Threshold=0.50':               list(metrics_default.values()),\n",
    "    f'Threshold={optimal_thr:.3f}': list(metrics_optimal.values())\n",
    "}).set_index('Metric')\n",
    "\n",
    "print('=' * 55)\n",
    "print('          DECISION TREE \u2014 FINAL RESULTS')\n",
    "print('=' * 55)\n",
    "print(f'  Best params:  {grid_search.best_params_}')\n",
    "print(f'  Tree depth:   {final_tree.get_depth()}')\n",
    "print(f'  Tree leaves:  {final_tree.get_n_leaves()}')\n",
    "print(f'  ccp_alpha:    {best_ccp_alpha:.6f}')\n",
    "print('-' * 55)\n",
    "print(summary.to_string(float_format='{:.4f}'.format))\n",
    "print('=' * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}