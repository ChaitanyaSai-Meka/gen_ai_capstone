{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
    "    ConfusionMatrixDisplay, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#0f0f1a',\n",
    "    'axes.facecolor': '#1a1a2e',\n",
    "    'axes.edgecolor': '#444466',\n",
    "    'axes.labelcolor': '#e0e0f0',\n",
    "    'xtick.color': '#aaaacc',\n",
    "    'ytick.color': '#aaaacc',\n",
    "    'text.color': '#e0e0f0',\n",
    "    'grid.color': '#2a2a4a',\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'font.size': 11\n",
    "})\n",
    "\n",
    "PALETTE = ['#7b5ea7', '#00c9a7', '#ff6b6b', '#ffd166', '#4ecdc4', '#a8dadc']\n",
    "PRIMARY   = '#7b5ea7'\n",
    "SECONDARY = '#00c9a7'\n",
    "DANGER    = '#ff6b6b'\n",
    "HIGHLIGHT = '#ffd166'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_data.csv')\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'\\nDtypes:\\n{df.dtypes}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Null counts:\\n', df.isnull().sum())\n",
    "print('\\nDuplicates:', df.duplicated().sum())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "counts = df['loan_status'].value_counts()\n",
    "bars = ax.bar(['No Default (0)', 'Default (1)'], counts.values,\n",
    "              color=[SECONDARY, DANGER], width=0.5, edgecolor='none')\n",
    "for bar, val in zip(bars, counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 200,\n",
    "            f'{val:,}\\n({val/len(df)*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontsize=11, color='#e0e0f0', fontweight='bold')\n",
    "ax.set_title('Target Class Distribution', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('Count')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['person_age', 'person_income', 'person_emp_exp',\n",
    "                'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
    "                'cb_person_cred_hist_length', 'credit_score']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    for status, color, label in zip([0, 1], [SECONDARY, DANGER], ['No Default', 'Default']):\n",
    "        axes[i].hist(df[df['loan_status'] == status][col], bins=40, alpha=0.65,\n",
    "                     color=color, label=label, edgecolor='none')\n",
    "    axes[i].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[i].legend(fontsize=8)\n",
    "    axes[i].yaxis.grid(True)\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "fig.suptitle('Numeric Feature Distributions by Loan Status', fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['person_gender', 'person_education', 'person_home_ownership',\n",
    "            'loan_intent', 'previous_loan_defaults_on_file']\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cat_cols), figsize=(22, 5))\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    default_rate = df.groupby(col)['loan_status'].mean().sort_values(ascending=False)\n",
    "    bars = axes[i].bar(default_rate.index, default_rate.values,\n",
    "                       color=PALETTE[:len(default_rate)], edgecolor='none')\n",
    "    for bar, val in zip(bars, default_rate.values):\n",
    "        axes[i].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.003,\n",
    "                     f'{val:.2%}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "    axes[i].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[i].set_ylabel('Default Rate')\n",
    "    axes[i].tick_params(axis='x', rotation=30)\n",
    "    axes[i].yaxis.grid(True)\n",
    "    axes[i].set_axisbelow(True)\n",
    "\n",
    "fig.suptitle('Default Rate by Categorical Feature', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "corr = df[numeric_cols + ['loan_status']].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(260, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, annot=True, fmt='.2f',\n",
    "            linewidths=0.5, linecolor='#0f0f1a', ax=ax,\n",
    "            annot_kws={'size': 9}, vmin=-1, vmax=1,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold', pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "age_cap   = df['person_age'].quantile(0.99)\n",
    "inc_cap   = df['person_income'].quantile(0.99)\n",
    "emp_cap   = df['person_emp_exp'].quantile(0.99)\n",
    "\n",
    "df = df[df['person_age']   <= age_cap]\n",
    "df = df[df['person_income'] <= inc_cap]\n",
    "df = df[df['person_emp_exp'] <= emp_cap]\n",
    "\n",
    "print(f'Shape after outlier removal: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_order = [['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate']]\n",
    "\n",
    "ordinal_features  = ['person_education']\n",
    "binary_features   = ['previous_loan_defaults_on_file', 'person_gender']\n",
    "nominal_features  = ['person_home_ownership', 'loan_intent']\n",
    "\n",
    "df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].map({'Yes': 1, 'No': 0})\n",
    "df['person_gender']                  = df['person_gender'].map({'male': 1, 'female': 0})\n",
    "\n",
    "X = df.drop(columns=['loan_status'])\n",
    "y = df['loan_status']\n",
    "\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "print(f'Class balance - 0: {(y==0).sum()}, 1: {(y==1).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')\n",
    "print(f'Train class balance: {y_train.value_counts().to_dict()}')\n",
    "print(f'Test  class balance: {y_test.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['person_age', 'person_income', 'person_emp_exp',\n",
    "                    'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
    "                    'cb_person_cred_hist_length', 'credit_score',\n",
    "                    'previous_loan_defaults_on_file', 'person_gender']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',      StandardScaler(),                             numeric_features),\n",
    "        ('ordinal',  OrdinalEncoder(categories=education_order),   ordinal_features),\n",
    "        ('nominal',  OneHotEncoder(drop='first', sparse_output=False), nominal_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',   LogisticRegression(\n",
    "        solver='saga',\n",
    "        max_iter=2000,\n",
    "        class_weight='balanced',\n",
    "        C=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training & Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_metrics = {}\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=metric, n_jobs=-1)\n",
    "    cv_metrics[metric] = scores\n",
    "    print(f'{metric:12s}: {scores.mean():.4f} (+/- {scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "metric_labels = list(cv_metrics.keys())\n",
    "means  = [cv_metrics[m].mean() for m in metric_labels]\n",
    "stds   = [cv_metrics[m].std()  for m in metric_labels]\n",
    "colors = [PRIMARY, SECONDARY, DANGER, HIGHLIGHT, '#4ecdc4']\n",
    "\n",
    "bars = ax.bar(metric_labels, means, yerr=stds, capsize=6,\n",
    "              color=colors, edgecolor='none', error_kw=dict(ecolor='#ffffff', lw=1.5))\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
    "            f'{mean:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylim(0, 1.12)\n",
    "ax.set_title('5-Fold Cross-Validation Metrics', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('Score')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "print('Model trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds  = np.linspace(0.01, 0.99, 200)\n",
    "f1_scores   = [f1_score(y_test, (y_proba >= t).astype(int)) for t in thresholds]\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(thresholds, f1_scores, color=PRIMARY, lw=2)\n",
    "ax.axvline(optimal_threshold, color=HIGHLIGHT, linestyle='--', lw=1.5,\n",
    "           label=f'Optimal threshold = {optimal_threshold:.3f}')\n",
    "ax.scatter([optimal_threshold], [f1_scores[optimal_idx]], color=HIGHLIGHT, s=80, zorder=5)\n",
    "ax.set_xlabel('Decision Threshold')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('F1 Score vs Decision Threshold', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal threshold: {optimal_threshold:.4f}')\n",
    "print(f'Best F1 at threshold: {f1_scores[optimal_idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default  = (y_proba >= 0.5).astype(int)\n",
    "y_pred_optimal  = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "def get_metrics(y_true, y_pred, y_prob):\n",
    "    return {\n",
    "        'Accuracy':  accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall':    recall_score(y_true, y_pred),\n",
    "        'F1':        f1_score(y_true, y_pred),\n",
    "        'ROC-AUC':   roc_auc_score(y_true, y_prob),\n",
    "        'PR-AUC':    average_precision_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "metrics_default = get_metrics(y_test, y_pred_default, y_proba)\n",
    "metrics_optimal = get_metrics(y_test, y_pred_optimal, y_proba)\n",
    "\n",
    "results_df = pd.DataFrame({'Threshold=0.50': metrics_default,\n",
    "                            f'Threshold={optimal_threshold:.3f}': metrics_optimal})\n",
    "print(results_df.to_string(float_format='{:.4f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, y_pred, title in zip(\n",
    "    axes,\n",
    "    [y_pred_default, y_pred_optimal],\n",
    "    ['Confusion Matrix (Threshold=0.50)', f'Confusion Matrix (Threshold={optimal_threshold:.3f})']\n",
    "):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='magma',\n",
    "                xticklabels=['No Default', 'Default'],\n",
    "                yticklabels=['No Default', 'Default'],\n",
    "                linewidths=1, linecolor='#0f0f1a',\n",
    "                annot_kws={'size': 13, 'weight': 'bold'})\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=10)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "axes[0].plot(fpr, tpr, color=PRIMARY, lw=2.5, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='#666680', linestyle='--', lw=1.2, label='Random Classifier')\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1, color=PRIMARY)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].yaxis.grid(True)\n",
    "axes[0].set_axisbelow(True)\n",
    "\n",
    "precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "axes[1].plot(recall_vals, precision_vals, color=SECONDARY, lw=2.5,\n",
    "             label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "axes[1].fill_between(recall_vals, precision_vals, alpha=0.1, color=SECONDARY)\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].yaxis.grid(True)\n",
    "axes[1].set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report (Optimal Threshold):')\n",
    "print(classification_report(y_test, y_pred_optimal,\n",
    "                             target_names=['No Default', 'Default']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance (Log-Odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_feature_names = (pipeline.named_steps['preprocessor']\n",
    "                     .named_transformers_['nominal']\n",
    "                     .get_feature_names_out(nominal_features)).tolist()\n",
    "\n",
    "all_feature_names = (numeric_features +\n",
    "                     ordinal_features +\n",
    "                     ohe_feature_names)\n",
    "\n",
    "coefs = pipeline.named_steps['classifier'].coef_[0]\n",
    "\n",
    "coef_df = (\n",
    "    pd.DataFrame({'feature': all_feature_names, 'coefficient': coefs})\n",
    "    .assign(abs_coef=lambda d: d['coefficient'].abs())\n",
    "    .sort_values('abs_coef', ascending=True)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, max(6, len(coef_df) * 0.35)))\n",
    "colors_bar = [DANGER if c > 0 else SECONDARY for c in coef_df['coefficient']]\n",
    "ax.barh(coef_df['feature'], coef_df['coefficient'], color=colors_bar, edgecolor='none')\n",
    "ax.axvline(0, color='#ffffff', lw=0.8, linestyle='--')\n",
    "ax.set_xlabel('Coefficient (Log-Odds)')\n",
    "ax.set_title('Logistic Regression Coefficients', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=DANGER, label='Increases default probability'),\n",
    "                   Patch(facecolor=SECONDARY, label='Decreases default probability')]\n",
    "ax.legend(handles=legend_elements, fontsize=9, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "top_coef = coef_df.sort_values('abs_coef', ascending=False).head(top_n)\n",
    "print(f'Top {top_n} most influential features (by |coefficient|):')\n",
    "print(top_coef[['feature', 'coefficient']].to_string(index=False, float_format='{:.4f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predicted Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for status, color, label in zip([0, 1], [SECONDARY, DANGER], ['No Default (0)', 'Default (1)']):\n",
    "    mask = y_test == status\n",
    "    ax.hist(y_proba[mask], bins=60, alpha=0.7, color=color, label=label, edgecolor='none')\n",
    "\n",
    "ax.axvline(0.5, color='#ffffff', lw=1.5, linestyle='--', label='Threshold = 0.50')\n",
    "ax.axvline(optimal_threshold, color=HIGHLIGHT, lw=1.5, linestyle='-.',\n",
    "           label=f'Optimal Threshold = {optimal_threshold:.3f}')\n",
    "ax.set_xlabel('Predicted Probability of Default')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Predicted Probability Distribution by True Class', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC', 'PR-AUC'],\n",
    "    'Threshold=0.50':                      list(metrics_default.values()),\n",
    "    f'Threshold={optimal_threshold:.3f}':  list(metrics_optimal.values())\n",
    "}).set_index('Metric')\n",
    "\n",
    "print('=' * 52)\n",
    "print('         LOGISTIC REGRESSION â€” FINAL RESULTS')\n",
    "print('=' * 52)\n",
    "print(summary.to_string(float_format='{:.4f}'.format))\n",
    "print('=' * 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
